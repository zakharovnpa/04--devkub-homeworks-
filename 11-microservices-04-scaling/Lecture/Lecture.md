## Лекция по теме "Микросервисы: масштабирование"

Михаил
ТриполитовМихаил Триполитов
Technical Lead
Михаил Триполитов

### 2План занятия       - 00:01:05
1. Scale Cube
2. Балансировка
3. Кэширование
4. Автомасштабирование
5. Service Discovery
6. Service Mesh
7. Итоги
8. Домашнее задание

### Хрупкость системы     - 00:01:40
* Распределение приложений по независимым серверам добавляет точки отказа, в которых что-то может пойит не так. 
  * Может быть физ. отказ сервера или его части какой-то
  * Нарушение связи между сервисами
  * Отказ БД или брокера сообщений
  * Ошибка в логик еработы самого сервиса или того фреймворка, на котором он построен
* При проектрировании и разработке систем нужно быть готовым к отказам и разрабатывать сервисы с учетом этих возможных отказов
* В некоторых крупных компаниях применяют подход к тестированию `Haose Monkey`. Это специальная отдельная система, которая случайным образом останавливает случайные сервера,
* разрвыает связи между случайными сервисами (и делает это в продакшене). Тем самым вынуждая разработчиков проектировать севисы с учетом возможных отказов.

### Способы защиты от хрупкости     -00:03:20
* Максимальное время ожидания (Timeout)
* Повтор запроса (Retry)
* Прерыватели цепи (Circuit Breaker)
* Перегородки (Bylkhead)
* Ограничитель кол-в запросов (Rate Limiter)
* Изоляция
* Идемпотентность

### Timeouts         - 00:04:00

Важно внимательно относится к выбору таймаутов для тех или иных операций.
Лучше использовать значения по умолчанию.
Необходимо логировать все ошибки таймаутов для анализа как нам лучше поступить - 
увеличить таймаут или доработать вызываемую сторону для того, чтобы она отвечала быстрее

![scaling_01](/11-microservices-04-scaling/Files/scaling_01.png)

### Повтор (Retry)       -00:06:18
Иногда это самый правильный способ отреагировать на ошибку или таймаут. Если была ошибка в одном экземпляре сервиса, то запрос поавдет на другой экземпляр
и успешно отработает.
Настраивать политику повторов надо аккуратно, чтобы не лопустить лишнюю нагрузку на сервис или систему, которая испытывает затруднения.


![scaling_02](/11-microservices-04-scaling/Files/scaling_02.png)

### Прерыватели цепи (Circuit Breaker)      -00:08:20
Эта техника позволяет обрабатывать ситуации, когда есть ошибка во внешнем сервисе и эта ошибка не должна влиять на поведение вызывающей системы и мы хотим снизить нагрузку на сервисы, испытывабщие проблемы.
* Как это работает:
  * освобождает ресурсы, которые начинают заниматься из-за возникшей ошибки

![scaling_03](/11-microservices-04-scaling/Files/scaling_03.png)

### Перегородки (Bylkhead) -00:12:00

Перегородки предотвращают чрезмероне использование ресурса, обеспечивая общую производительность на достаточном уровне.
Этот подход можно реализовывать по разному. Обычно это выделение ограниченного кол-ва ресурса. Похоже на изоляцию с ограничением CPU, RAM.

![scaling_04](/11-microservices-04-scaling/Files/scaling_04.png)

### Ограничитель кол-в запросов (Rate Limiter) -00:13:25
Ответчает ошибкой в случае превышения порога. Часто применяют облачные сервисы для ограничения потребляемых ресурсов.
Есть привязка к аккаунту для контроля ресерсов на каждого потребителя.
Применяется в локальных системах. Лучше ответить ошибкой, чем полным отказом системы.

![scaling_05](/11-microservices-04-scaling/Files/scaling_05.png)

### Изоляция -00:15:30
Каждому сервису выделяют определенное кол-во ресурсов для исключения превышения их использования.
Сейчас изоляцию реализуют через контейнеры Kubernetis или другие оркестраторы

### Идемпотентность

### Масштабирование  -00:17:45
Работа с ошибками нужна для того, чтобы у нас было много экземпляров разных сервисов и по сути это называется масштабированием.
* Две причины при которых может потребоваться масштабирование:
  * Защита от проблем. В случае отказа одного сервиса - запустить другой экзеипляр сервиса.
  * Выдерживать бОльшую нагрузку. Обрабатывать больше запросов и быстрее.
* Вертикальное масштабирование:
  * Многие процессы могут быть улучшены за счет добавления вычислительных мощностей (CPU, RAM, Video).
  * Это дорого. Один большой сервер может быть дороже, чеи два маленьких с совокупной мощность как у большого сервера
  * К более мощным серверам необходимо адаптировать ПО, что тоже увеличивает фин. затраты.
* Выходом является Горизонтальное маштабирование, когда независимые микросервисы распределяются по разным хостам. Тем самым распределяя нагрузку и риски.


### 3Scale Cube  -00:19:50
Для того, чтобы оценивать возможности масштабирования есть подход "Scale Cube"

### 4Scale Cube
* Ось Z - масштабирование через разделение данных: каждая запущенная копия сервиса отвечает за своё подмножество данных
* Ось Y - масштабирование разделением приложения: функции выделяются в отдельные сервисы и запускают независимо друг от друга
* Ось X - горизонтальное масштабирование: запуск нескольких копий приложения

![scaling_06](/11-microservices-04-scaling/Files/scaling_06.png)


### 7Балансировка -00:21:30

### 8Балансировщик нагрузки
Основная функция: распределение входящих запросов
по нескольким серверам
Сервисы
Балансировщик
нагрузки
Входящий
трафик

![scaling_07](/11-microservices-04-scaling/Files/scaling_07.png)

### 9Балансировка Дополнительные функции
- Терминация SSL
- Активация резервных серверов
- Ассиметричное распределение запросов
- Защита от DDOS атак
- Gzip cжатие HTTP
- Проверка работоспособности конкретных экземпляров
- Кэширование HTTP
- Контентно зависимое распределение запросов
- Аутентификация клиентов
- Фильтрация контента

![scaling_08](/11-microservices-04-scaling/Files/scaling_08.png)

### 10Балансировщики  -00:22:25
Балансировщики
- Nginx - стандарт для балансировщика. Очень быстрый и надежный сервис
- F5 
- Kemp 
- HAProxy 
- Envoy - балансировщик и сервис Мэш

Облачные балансировщики
- AWS Elastic Load Balancer
- Google Cloud Load Balancing
- Azure Load Balancer
- Yandex Cloud Network Load Balancer


![scaling_09](/11-microservices-04-scaling/Files/scaling_09.png)

### 11Системы обработки задач  -00:24:15
Это штука, которая основывается на какой-то шине данных

* Конкурентные обработчики задач
* Генераторы задач
* Брокер сообщений (Kafka, RabbitNQ)

Вместо брокера сообщений может быть систему управления задач. Например Зукипер.

В результате создания задачи она попадает в некую очередь. Из очереди обработчики берут каждый свою задачу и обрабатывают.
Есть буфер для регулирования загрузки. Задач может быть много, очередь накапливается. Задачи поступают быстрее и обработчиков надо добавлять. 
Осчередь может не прибавляться. Это хорошо тем, что можно просто добавить обработчика. Не затрагивая инфраструктуру.
Это хорошо подходит для пакетных задач. Для синхронной обработки большого файла. Для асинхронных задач не требующих мгновенного ответа потребителю.
Позволяет разделить генератор задач и обработчики задач. В пиковую нагрузку увеличивается кол-во обработчиков и система не деградирует. Можно следить за кол-вом задач в очереди. Можно при нагрузке алертить для увеличения обработчиков. такая система хорошо подходит для автоматического масштабирования


![scaling_10](/11-microservices-04-scaling/Files/scaling_10.png)

### 12Кэширование  -00:29:00
Это наиболее распространенный способ повышения производительности. Существует множество разных подходов к кэшированию.

### 13Кэширование
Кэширование - наиболее распространенный способ повышения производительности
* Клиентский кэш - когда данные сохраняются на клиенте на какоет-время. Кэш запроса.
* Сквозной кэш. Между потребителем и сервером стоит реверс-прокси (нджинкс) например. Запрс в сервси не отправляется.
* Прогретый кеш. Данные спец. подготовленные для отдачи потребителю. Полностью исключается нагрузка на сервер. Повышается сложность системы, но повышается ее надежность.

![scaling_11](/11-microservices-04-scaling/Files/scaling_11.png)

### 14Кэш встроен в сервис

В сервисе выделяется память. Область памяти. Оперативная память. И данные кешируются прямо в память сервиса. Это простой подход. Мминусы: Затраты памяти на кширование. И может быть промах мимо кеша сервиса, если на каком-то экземпляре сервиса нет кеша.


![scaling_12](/11-microservices-04-scaling/Files/scaling_12.png)

### 15Распределенный кэш  -00:31:00 ё -00:33:15
Одно из самых распространенных решений. Неасмторя на точто требует доп. инфраструктуру. Требуется пул машин с большим объкемом памяти с БД. Минуус- необходимо строить кластер. Плюс - независит от того куда пришел запрос. Кеш большой и. Этот кластер обеспечивает надежное хранение данных даже с учетом распределения на нескольких нодах кластера. И при выходеи з строя одной из нод данные все ра вно сохраняются. Веорятность потери данных из кэша не кртичны. Часто кеш дает очень большой прирость производительности. И без кеша система может не выдержать нагрузку.

![scaling_13](/11-microservices-04-scaling/Files/scaling_13.png)

### 16Прогретый кэш   -00:36:00
Самая сложная схема. Цель - снять нагрузку с сервисов, выполняющие запросы и перейти к получению заранее подготовленных данных.
После запроса от сервиса результат попадает в очередь и потом данные считываются прямо из кэша. Штука очень сложная в овсех аспектах. Такой подход нужен для обработки больших нагрузок на запись и на чтение. ПАоток на запись отделяется от потока на чтение. Мы изолируем их друг ото друга.
Дя поддержания актуальности данных в кеше используется технология актуалллизации данных в кеше.Эвеншиал консинсести. Все зависио от наших задач и от скорости обработки данных.


![scaling_14](/11-microservices-04-scaling/Files/scaling_14.png)

### 17Кэширующий балансировщик   -00:32:30

Часто встречающийся и простой вариант. Ограничен объемом памяти на одной машине. Не имеет промахов.

![scaling_15](/11-microservices-04-scaling/Files/scaling_15.png)

### 18In-Memory Кеш   -00:41:15
Когда говорим про прогретый кеш всегда упоминают ин-мемори БД:
- Hazelcast
- Redis
- Memchached
- Tarantool

Также имеется возможность работы с кешами и у традиционных  классических реляционных БД
- Postrees
- MSSQL
У них есть ин-месори таблицы, которые ведут себя также как ин-мемору БД, просто они живут в рамках реляционной среды. А по сути - тоже самое временное хранение данных.

### 19Автомасштабирование   -00:42:00

### 20Автоматическое масштабирование
Использует преимущества эластичной облачной среды. Можно лоучить тот объем ресурсов что необходим в конкретный момент времени. При автоматическом масштабировании говорят о горизонтальном масштабировании. Система должна поддерживать возможность горизонтального масштабирования

- Процесс динамического выделения ресурсов для удовлетворения требований производительности:
  - При увеличении нагрузки выделяются дополнительные ресурсы для обеспечения соглашения об уровне обслуживания (SLA)
- При снижении нагрузки
  - освобождаются ресурсы для экономии средств


![scaling_16](/11-microservices-04-scaling/Files/scaling_16.png)

### 21Необходимые компоненты   -00:43:07
Для обеспечения автоматического масштабирования

- Мониторинг приложений и инфраструктуры. Сколь потребляется ресурсов, сколько может обработать один экземпляр
- Логика принятия решений. Система принятия решения о масштабировании.
- Управление ресурсами. Система управления
- Тестирование процедуры автомасштабирования

### 22Подходы   -00:44:20


- Динамическое масштабирование на основе метрик приложения или инфраструктуры:
  - Среднее значение CPU
  - Общее количество запросов
  - Длительность обработки задачи
  - Количество запросов завершившихся ошибкой
  - комбинация все этих версий
- Масштабирование по расписанию
  - Когда есть система которая запускает столко сервисов для выдерживания нагрузки по расписанию
  - Когда знаем паттерны поведения наших пользователей
- Предсказательное масштабирование
  - Нейронные сети которые предсказывают когда и сколько надо ресурсов

### 23Автомасштабирование   -00:47:10
Системы для автомасштабирования. В основном это облачные решения, т.к. все завязано на наличие свободных ресурсов для выделения новых экземпляров сервиса при высоких нагрузках. Их можно купить на время. При локальных решениях ресурсы уже куплены.
Многое зависит от задач и от компании как она работает.

- Kubernetes Horizontal Pod Autoscaler
- Amazon EC2 Auto Scaling
- Azure Monitor
- Google Compute Engine Autoscaling
- Yandex Cloud Cluster-Autoscaler

### 24Service Discovery 

### 25Service Discovery  -00:49:00
Это способ найти сервис, который мы хотим вызвать. Куда напрваить запрос для получения ответа. Этот сервис дает в ответ айпи адрес сервиса, который мы ищем.
В зависимости от задач системы, сложности и целей выбирается какой-то из вариантов.

* Настройки
  * У клиентов в конфигурации IP адреса сервисов с которыми ему нужно взаимодействовать
* DNS
  * У каждого сервиса есть DNS имя за которым несколько IP адресов его запущенных экземпляров
* Service Registry
  * Специальное программное обеспечение (Service Registry) позволяет сервисам при старте зарегистрировать адреса запускаемого экземпляра, а клиентам получить эти адреса по имени

### 26Service Registry   -00:51:00
Есть два варианта обеспечения коммуникации:
Основа одна - регистрация сервиса в сервис реджистри. Потом клиент идет в реджистри и получает адрес сервиса. Такие запросы может делать балансировщик.


![scaling_17](/11-microservices-04-scaling/Files/scaling_17.png)

### 27Service Registry на балансировщике


![scaling_18](/11-microservices-04-scaling/Files/scaling_18.png)

### 28Service Registry   -00:52:10


- Zookeeper
- Consul
- Eureka
- Самодельный

### 29Service Mesh    -00:52:58
Это новый подход связанный с оркестраторами контейнеров (кубернетис) и он позволяет управлять трафиком в нутри структурв
Обеспечивает доставку трафика. Обеспечивает безопасность. Реализует ссложные запросы, реализуемые на их контексте. Блю грин как раз на этом и реализуется.


### 30Задачи Service Mesh
- Гибкость настройки взаимодействия сервисов на уровне инфраструктуры, управление трафиком, балансировка
- Унифицированный мониторинг большой системы
- Повышение безопасности: отсутствие риска перехвата трафика, полный контроль над сетью, исключение угроз при работе в
нескольких дата центрах или публичных облаках
- Упрощение реализации сложных шаблонов развертывания приложений: Blue/Green, Canary, A/B Tesing
- Организация взаимодействия сервисов в мульти кластерной среде

### 31Принцип работы Service Mesh на примере Istio   -00:57:05
Есть сайткард для каждого сервиса он живет на уровне кода в кубернетесе. А сайдкард реализует управление.

Схема с сайта https://istio.io/latest/docs/concepts/what-is-istio

![scaling_19](/11-microservices-04-scaling/Files/scaling_19.png)

### 32Service Mesh   -00:57:55
Варианты для организации  Service Mesh. Геораспределение по датацентрам. Сложные схемы развертывания.
Более четкий контроль трафика.
- Istio
- Linkerd
- Consul Connect
- Kuma
- Maesh
- OpenShift Service Mesh
- AWS App Mesh

### 33Итоги
- Узнали важность непрерывной поставки для микросервисной
архитектуры
- Познакомились со способами развертывания микросервисов
- Узнали про разные виды тестирования и изучили влияние пирамиды
тестирования на результат
- Разобрали разные способы обеспечения аутентификации и авторизации
- Познакомились со способами мониторинга: метрики, логи, трассировка
- Обсудили масштабирование и кэш

### 34Домашнее задание
Давайте посмотрим ваше домашнее задание.
- Вопросы по домашней работе задавайте в чате мессенджера Slack.
- Задачи можно сдавать по частям.
- Зачёт по домашней работе проставляется после того, как приняты
все задачи.

### 35Задавайте вопросы и
пишите отзыв о лекции!
Михаил Триполитов
Михаил ТриполитовClient

### Shard 1
Replica 2
VM 1
Replication
Shard 2
Replication
Shard 3
Replication
Replica 3
VM 2
Replica 1
VM 3
