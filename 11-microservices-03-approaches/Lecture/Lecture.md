## Лекция по теме "Микросервисы: подходы"


Михаил
ТриполитовМихаил Триполитов
Technical Lead
Михаил Триполитов

### 2План занятия
1. Развертывание
2. Тестирование
3. Безопасность
4. Мониторинг
5. Итоги
6. Домашнее задание

### 3Развертывание
#### 4Непрерывная интеграция      - 00:01:25
> Цель непрервыной интеграции - проверить, что при изменении кода не сломались существующие функции
> Это обеспечивается сборокй и прогоном тестов при каждом коммите в репозитории.
> В результате такой сборки создаются артефакты (образы), которые используются в дальнейших шагах (тестах и развертываниях)
> Это все нужно для того, чтобы быть уверенным, что на проде запускается именно то, что протестировано и нормально работает.

* Здесь важно:
  * Быстрая обратная связь к разработчику, если тесты не прошли
  * Исключение челевеческого фактора при тестировании, т.к. тесты и сборка автоматизированы и выполняются всегда на одной той же среде, исключая ошибки среды.
  * Повторяемость. Всегда есть возможность пересоздать артефакт. Код находится в системе котроля версий, шаги сборки CI/CD - тоже там (может быть в разных системах)
  * В любой момент мы можем создать артефакт из исходников

Сборка
Сервер
непрерывной
интеграции
Система
контроля
версий
Тестирование
Результат
Commit
Результат
Команда разработки

![approaches-01](/11-mikroservices-03-approaches/Files/approaches-01.png)

#### 5Непрерывная интеграция и микросервисы      - 00:05:10

> В микросервисной архитектуре непрерывная интеграция становится обязательной.
> Когда много сервисов, без автоматизации не обойтись для снижения влияния человеческого фактора на процесс поставки артефакта сборки и дальше на поставкку сервисов на прод.

* Когда много сервисов, то есть разные подходы:
  * Можно хранить код всех сервисов в одном большом репозитории и на каждый комит каждого сервиса собирать все что есть в этом репозитории
  * Можно хранить код всех сервисов в одном репозитории (-00:06:10 неразборчиво) и в папке отдельного коммита даст сборку только этого сервиса
  * Можно хранить код каждого сервиса в отдельном репозитории и для каждого сервиса настривать отдельную конфигурацию для сборки. Этот вариант наиболее выгодный.
  > Сервисы становятся независимыми друг от друга, начиная с кодовой базы и заканчивая артефактом сборки. У каждого сервиса свой артефакт. И они могут друг с другом общаться только через API. 
* Когда у нас очень много микросервисов, то для упрощения работы с такой схемой используют подходы, упрощающие создание и настройку сервисов.
  *  Это и автоматические способы по созданию и нименованию репозиториев, артефактов, конфигураций. Это конвенции и правила именования всего, что толко относится к сервису.
  *  Это может распространяться на другие аспекты - на мониторинг, сбор логов, трассировку, конфинурацию.
  *  У всех сервисов должен быть единый подход к именованию всех сущностей, которые относятся к сервису. Иначе будет сложно и разработчикам и эксплуатации  в том, что происходит в системе
  * Следующий аспект когда у нас один репозитори - один сервис это наличие у команды шаблонов структуры репозиториев для разных типов сервисов и разных стеков. Для того, чтобы каждый сервис в коде выглядел похоже. Чтобы был одинаковый набор папок, чтобы файлы назывались похоже, чтобы настройки для сборки были одинаковы и т.д.
  * Третий важный аспект - шаблоны конфигурации сборок с ситсеме сборки (например,в TeanCityесть шаблон, который можно подключать к репозиторию). Т.е. у нас есть много билд-конфигураций, набор шагов сборки у них одинаковый и которые настраиваются в зависимости от того к какому шаблону сборки они подключены

- 00:09:04 - 
- Таким образом подход "один сервис - один репозиторий" позволяет достичь максимальную независимость сервисов и при этом, если применить схемы по упрощению работы с большим кол-вом репозиториев у нас не слишком сильно усложнится система непрерывной интеграции.


Система хранения версий
Сервер непрерывной
интеграции
Service 1 Code Service 1 Build
Service 2 Code Service 2 Build
Service 3 Code Service 3 Build
Код каждого сервиса
хранится в отдельном
репозитории
Система хранения артефактов
Service 1
Version 1.2.3
Service 2
Version 2.0.7
Service 3
Version 1.0.1
Для каждого сервиса собирается
отдельный артефакт

![approaches-02](/11-mikroservices-03-approaches/Files/approaches-02.png)

### 6Непрерывная поставка       - 00:09:30
> Continues Delivery - это подход к разработке ПО, при котором оно производится кототкими итерациями и гарантирует, что ПО является стабильным и может быть передано в эксплуатацию в любое время. Но при этом сама передача обычно происходит вручную.
> Т.е. у нас есть такая система доставки, в которой по факту комита выполняется сборка, прогоняются юнит-тесты, после этого артефакт передается на приемку,
> в которой артефакт устанавливается на тестовую приемку (тоже может быть автоматически), прогоняются интеграционные тесты, нагрузочные тесты, и после подтвержения, что артефакт готов к выходу в прод уже вручную осуществляется его развертывание.
> Обычно для этого есть отдельная процедура (Релиз или что-такое). И информация об артефакте остается в системе учета задач

Код
Авто
Сборка
Авто
Тесты
●
●
●
●
Авто
Вруч
ную
Приёмка
Выкладка
Установка на тестовый контур
Интеграционные тесты
Нагрузочные тесты
Ручные тесты

![approaches-03](/11-mikroservices-03-approaches/Files/approaches-03.png)

### 7Непрерывная установка      -00:11:10
> Continues Deployment - этот подход использует автоматическое тестирование для проверки иззменений в коде на отсутствие регресса, на оостутствие повторений существующих ошибок и возникновение новых ошибок в существующем коде.
> И после автоматической проверки следует автоматическия установка ПО на продуктовый контур
* Continues Deployment - это следующий этап, к оторому следует стремится при разработке системы, основанной на микросервисах
Код
Авто
Сборка
Авто
Тесты
●
●
●
Авто
Авто
Приёмка
Выкладка
Установка на тестовый контур
Автоматические интеграционные тесты
Автоматические нагрузочные тесты

![approaches-04](/11-mikroservices-03-approaches/Files/approaches-04.png)


### 8Стенды / Контура       - 00:13:10
* Появляется необходимость доставки и развертывания на разные среды, предназначенных для различных целей
  * Стенд для приемочного тестирования
  * Стенд для команды разработки
  * Стенд для интеграционного тестирования между командами
  * Стенд для ручных тестировщиков
  * Боевой стенд
* Между стендами должно быть как можно меньше отличий по мере приближения к боевому.
* Это важно оптому, что в зависимомти от среды ПО может вести себя по разному
* Стараются держать хотябы одну тестовую среду полностью идентичную боевой среде и по настройкам и по ресурсам

* Управление стендами = это сложный и кропотливый процесс с вниманием к деталям

CI
Dev
Непрерывная сборка
● Сборка кода
● Unit-тесты
● Публикация артефактов сборки
Integration
UAT


Production


![approaches-05](/11-mikroservices-03-approaches/Files/approaches-05.png)

#### 9Непрерывное развертывание      -00:16:55
Варианты обновления сервисов на проде:
- Recreate
- Rolling deployment
- Blue-Green deployment
- Canary releases
- A/B testing
- Shadow

Стараются делать так, чтобы за одно изменение изменялся только один сервис

### 10Recreate      -00:18:18
Один из свмых простых способов.
Данный способ возможен при полной остановк всех сервисов. Значит есть простой в работе сервисов.
Также есть проблема в том, что при возникновении ошибок надо откатывться или чинить ошибку.
Это высокорисковый вариант при возникновении ошибки в процессе выкладки.
Но этот способ самый простой, дешевый и быстрый с точки зрения организации.
Такой подход можно использовать для вспомогательных систем у которых нет необходимости в постоянной и непрерывной работе, либо когда у системы есть интервалы, когда системой не пользуются.


До После
v1.0 v2.0
![approaches-06](/11-mikroservices-03-approaches/Files/approaches-06.png)

#### 11Мультисервис Recreate      - 00:20:00
При этом варианте происходит одновременное обновление нескольких сервисов. Это более рискованный вариант в случае ошибок в нескольких сервисах.
Вариант простой дешевый и быстрый. Неустойчив к ошибкам. С трудность в откатах.
После обновления нужно проверять каждый сервис чтобы все работало. Это может быть сложным, т.к. мы меняем много частей сразу.
Надо стараться минимизировать изменения. Для снижения риска сильного влияния на всю систему при ошибке.

До
v1.0
v2.7
После
v1.3
v3.8
v1.1
v2.8
v1.5
v4.0

![approaches-07](/11-mikroservices-03-approaches/Files/approaches-07.png)

#### 12Rolling deployment      -00:21:12
Это дефотный вариант для обновления версий подов в Kubernetes.
Постепенная замена всех экземпляров системы на новую версию.
Достаточно простой способ (из коробки) во многих системах.
Откат на предыдущую систему достаточно прост
Меньше риск при ошибке. Она может проявиться на для всех пользователей сразу.

* Минусы такого подхода:
  * необходимо обеспечить поддержку и работу одновременно разных версий сервисов
  * более длительный способ с точки зрения реализации обновления
  * 

После
До
1 Node
2 Nodes
OK?
v1.0
4 Nodes
3 Nodes
OK?
5 Nodes
OK?
6 Nodes
OK?
v2.0

![approaches-08](/11-mikroservices-03-approaches/Files/approaches-08.png)

#### 13Blue Green deployment     - 00:23:00

Используются два идентичных контура (Blue. Green). Один из контуров находится в работе, обрабатывает запросы. Другой контур работает, но не обрабатывает запросы (Standby). На контур в состоянии Standby устанавливается обновление и трафик переключается на него. Если ошибок нет, то так он и остается в работе. Если нет, то трафик переключается на первоначалный контур, Потом вносим исправления и опять пытаемся обновиться.

* Плюы такого подхода:
  * Мгновенное переключение и мгновенный откат при ошибках, т.к. у нас на стенде работают обе версии
* Минусы:
  * Необходимо содержать два идентичных контура (это может быть дорого)
  * Сложность развертывания сервисов с состоянием. Две версии сервисов должны работать одновременно. Только на уровне кластеров.
  * Есть риск потери запросов при переключении стенда, DNS или балансировщика
Blue Green deployment  достаточно популярный вариант.

До
После
Stand by Live Live Stand by
v1.2 v1.1 v1.2 v1.1

![approaches-09](/11-mikroservices-03-approaches/Files/approaches-09.png)

#### 14Canary deployment     - 00:24:50
Это больше подходы к выкладке, а не про обновление целиком. Скорее это техники для того, чтобы разворачивать сервис и выполнять дополнительные функции.
Канареечная выкладка характеризуется тем, что происходит направление запросов пользователей с одной версии на другую. Т.е. оно производится постепенно.
Здесь могут выделять специальную группу пользователей (Бетта тестирование). Может быть выбирается случайно какой-то % пользователей.
На трафике этих пользователей пытаются понять все л и нормально или нет. Выявляют ошибки, исправляют и т.д. опять обновляют пока все ошибки не исправят.
Далее можно постепенно увеличивать % пользователей, либо воспользоваться стандартными подходами, но более простыми: Rolling Deployment, Recreate, Blue Green.

* Плюсы такого подхода:
  * Простота отката
  * Возможность тестировать новый функционал, сервисы, гипотезы на небольшом % пользователей
  * Это дешевле Blue Green. Не нужно держать два стенда.
  * Наименее рисковый вариант с учетом цены.

* Минусы:
  * Должно пройти какое-то врмя прежде чем мы поймем что что-то не так
  * Сложность настроек для некоторых ситуаций
  * Необходимость работы одновременно нескольких разный версий
  * Длительность прверки после каждого шага обновления

До
После
10% запросов
70% запросов
OK?
v1.0
v1.1
v1.0
100% запросов
OK?
v1.1
v1.0
v1.1
![approaches-10](/11-mikroservices-03-approaches/Files/approaches-10.png)

#### 15A/B Testing   -0:28:45
Разные версии одного и того же сервиса могут одновременно работать кна одном и том же контуре в пределах фиксированного промежутка времени.
По результатам этих экспериментов должны быть собраны какие-то метрики для понимания того что эксперимент удачный или нет. И какой и звариантов нам подходит.
Это необязательно про Deployment. Мы гоаорим про развертывание.
Можно таким образом развертывать сервисы для эксперимнетов.

* Минусы: 
  * Сложность всей этой настройки
  * Итоги тестирования надо собирать и анализировать. А для этого нужны отдельные инструменты
  * Без распределенной трассировки здесь не обойтись. Иначен е будет понятно сервис с какой вервией как отработал

После
До
v1.2(B)
71%
v1.3 (D)
73%
v1.2 (C)
63%
v1.0
v1.0 (A) = 71%
v1.3

![approaches-11](/11-mikroservices-03-approaches/Files/approaches-11.png)

#### 16Shadow     -00:32:43

Теневое развертывание.
Используется для тестирования сервисов, используя боевые запросы.
При получении запроса балансировщик отправляет их на обе версии сервиса. Пользователю отправляется ответ от актуальной версии, а ответ от новой версии игнорируется или используется для сравнения с ответтом от текущей версии. Так можно увидеть регресс, измерить призводительность.
* В основном этот подход применяется для тестирования используюя боевой трафик, при этом никак не влияя нп ользователей.
* Выкатка на пользователей производится только после достиженя требований по стабильности и производительности.

* Минусы:
  * Дорого
  * Сложно в настройке
  * Анализировать сложно

Если мы занимаемся заменой какого-то сервиса, то это хороший вариант в плане того, что мы можем на боевом трафике проверить, что наш сервис, написанный по-новому (на новом языке, с новыми алгоритмами) работает с точки зрения внешнего потребителя точно так же как и предыдущая версия.
До
v1.0
После
v1.0
v2.0
![approaches-12](/11-mikroservices-03-approaches/Files/approaches-12.png)

#### 17Непрерывное развертывание      - 00:34:40

* Выводы про развертывание.
  * Rolling Deployment, Blue Green - это лучшие варианты и стратегии, которые можно использовать в бою.
  * Blue Green и Shadow требуют дополнительный набор ресурсов. Blue Green - двойного, что сильно влиятяет на бюджет


|Стратегия|Отсутствие остановки|Тестирование на реальных запросах|Тестирование действий пользователей|Стоимость|Длительность отката|Влияние на пользователей|Сложность|
|-|-|-|-|-|-|-|-|
Recreate| ❌|❌|❌| 💲 |🕔🕔🕔| 󰣻󰣻󰣻 |
Rolling| ✔| ❌| ❌| 💲 |🕔🕔🕔| 󰣻 |🔬
Blue Green| ✔ |❌| ❌| 💲💲💲 ||󰣻󰣻 |🔬🔬
Canary| ✔ |✔| ❌| 💲 |🕔 |󰣻 |🔬
A/B Testing| ✔ |✔| ✔| 💲 |🕔| 󰣻 |🔬🔬🔬
Shadow| ✔| ✔| ❌| 💲💲💲|||🔬🔬🔬

![approaches-13](/11-mikroservices-03-approaches/Files/approaches-13.png)

### 18Тестирование      - 00:36:05

#### 19Типы тестов
* Главное:
  * Микросервисы базируются на автотестах, иначе автоматического развертывания и доставки добиться не получится. Просто потому что ручное тестирование долго и не надежно.

* Квадрант тестирования:
  * Технологические тесты помогают разрабочикам создавать систему
  * Бизнес направленные тесты. Они помогают неискушенным в технологиях удостовериться в работе систем

Предпочтение надо отдавать небольшим легкоповторяемым автоматизированным тестам
Иногда на обойтись и без ручных тестов, низкоуровневого.

В микросервисной системе, если от нее зависит жизнь и здоровье человека необходимо использовать автотестирование

![approaches-14](/11-mikroservices-03-approaches/Files/approaches-14.png)

### 20Пирамида тестирования    - 00:39:05
* Пирамида показывает пропорции в которых нужно использоват тесты
  * End to End тесты дают больше уверенности в правильном поведени систем, их функциональности. Но такие тесты дорогие и медленные. Должно быть не много.
  * Unit Test быстрые и дешевые, но они проверяют код в изоляции от остального кода. Таких тестов должно быть много чтобы определить что у нас все работает так как нужно
  * Service


![approaches-15](/11-mikroservices-03-approaches/Files/approaches-15.png)

### 21Тесты - часть процесса развертывания   -00:41:25

Тесты должны быть частью сборки и развертывания (пайплайн). Чем раньше система упадет, если в ней есть ошибка, тем это лучше.
Не должны запускаться интеграционные тестирования, если не прошли юнит-тесты. Пока разработчик не починил юнит-тест, дальше пайплай не должен идти.
Задача DevOps- обеспечить работу пайплайн. А тесты пишут или разработчики или тестироващики.

Unit Tests
Service Tests
End to End Tests
Цепочка-сборка
прерывается как
можно раньше, чтобы
сократить время
обратной связи.

![approaches-16](/11-mikroservices-03-approaches/Files/approaches-16.png)

### 22Безопасность    - 00:42:50

### 23Аутентификация и авторизация
- Идентификация - процедура выявления идентификатора субъекта в системе
- Аутентификация - процедура проверки подлинности
- Авторизация - процедура проверки прав на выполнение определенных операций

### 24Single Sign On
Login 1 Service 1 Service 1
Login 2 Service 2 Service 2
SSO
Login 3 Service 3 Service 3
Login 4 Service 4 Service 4

### 25Межсервисная аутентификация и авторизация
2. Пользовательский токен
1. Без авторизации
4. OAuth
3. Простая HTTP авторизация
Service 1
Service 2
5. Client Certiﬁcates
6. HMAC
7. API Keys

### 26Без аутентификации
schema://host:port
Service 1
Service 2

### 27Propagate User Identity
login + password
schema://host:port
SSO
Client Token
Service 1
Service 2

### 8HTTP Basic Auth
https://host:port
Authorization: Basic base64(<username>:<password>)
Service 1
Service 2
HTTPS Server
Certiﬁcate
Private Key
Поиск логина и пароля в Базе Данных

### 29OAuth2
Client Credentials
OAuth2 Service
access_token
Service 1
Service 2
https://host:port
Authorization: Bearer <access_token>

### 30Client Certiﬁcates
Certiﬁcate Authority
Verify Server Certiﬁcate
Client
Certiﬁcate Server
Certiﬁcate
Public Key Public Key
Service 1
Service 2
Server
Certiﬁcate
Client
Certiﬁcate
Private
Key
Verify Client Certiﬁcate
https://host:port
Private
Key

### 31Hash-based Message Authentication Code (HMAC)
https://host:port
Authorization: HMAC-SHA256 <id>:<signature>
Service 1
Service 2
id
secret
id
id secret
id
id secret
secret
secret
CanonicalRequest
Timestamp
+ HTTP Verb
+ Canonical URL
+ Canonical Query String
+ Canonical Headers
+ Signed Headers
+ hash(SHA256, Payload)
Signature Calculation
StringToSign
“HMAC”
+ Timestamp
+ hex(hash(SHA256, CanonicalRequest))
Signature
hex(hmac(SHA256, secret, StringToSign))

### 32API Keys
1. Заголовок
https://host:port
X-API-Key: 2fb96c97-d401-475a-8f12-ed7b9346fedb
2. Строка запроса
https://host:port?api_key=2fb96c97-d401-475a-8f12-ed7b9346fedb
Service 1
Service 2
Верификация API Key по Базе Данных

  
### 33Межсервисная аутентификация и авторизация
1. Без авторизации
2. Пользовательский токен
3. Простая HTTP авторизация
4. OAuth
5. Client Certiﬁcates
6. HMAC
7. API Keys

### 34Мониторинг

### 35Сбор метрик
Host 1
Host 2
Каждый сервис
публикует метрики
Host N
На регулярной основе
считывает и сохраняет
значения метрик
http://host/metrics
Prometheus
Graphana
InﬂuxDb

### 36Сбор логов
Host 1 Host 2 Host N
Application
log Application
log Application
log
Logstash Logstash Logstash
Elastic Search Kibana

### 37Сбор трассировки
Host 1 Host 2 Host N
Jaegеr Agent Jaegеr Agent Jaegеr Agent
Jaegеr Collector
Cassandra
Jaegеr UI

### 38Мониторинг
1. Сбор метрик
2. Сбор логов
3. Сбор трассировки
Важно стандартизировать метрики, логи и трассировку
для всех сервисов.

### 39Итоги
● Узнали важность непрерывной поставки для микросервисной
архитектуры
● Познакомились со способами развертывания микросервисов
● Узнали про разные виды тестирования и изучили влияние пирамиды
тестирования на результат
● Разобрали разные способы обеспечения аутентификации и авторизации
● Познакомились со способами мониторинга: метрики, логи, трассировка

### 40Домашнее задание
Давайте посмотрим ваше домашнее задание.
● Вопросы по домашней работе задавайте в чате мессенджера Slack.
● Задачи можно сдавать по частям.
● Зачёт по домашней работе проставляется после того, как приняты
все задачи.

### 41Задавайте вопросы и
пишите отзыв о лекции!
Михаил Триполитов
Михаил Триполитов
