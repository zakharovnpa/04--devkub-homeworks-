## Лекция по теме "Микросервисы: подходы"


Михаил
ТриполитовМихаил Триполитов
Technical Lead
Михаил Триполитов

### 2План занятия
1. Развертывание
2. Тестирование
3. Безопасность
4. Мониторинг
5. Итоги
6. Домашнее задание

### 3Развертывание
#### 4Непрерывная интеграция      - 00:01:25
> Цель непрервыной интеграции - проверить, что при изменении кода не сломались существующие функции
> Это обеспечивается сборокй и прогоном тестов при каждом коммите в репозитории.
> В результате такой сборки создаются артефакты (образы), которые используются в дальнейших шагах (тестах и развертываниях)
> Это все нужно для того, чтобы быть уверенным, что на проде запускается именно то, что протестировано и нормально работает.

* Здесь важно:
  * Быстрая обратная связь к разработчику, если тесты не прошли
  * Исключение челевеческого фактора при тестировании, т.к. тесты и сборка автоматизированы и выполняются всегда на одной той же среде, исключая ошибки среды.
  * Повторяемость. Всегда есть возможность пересоздать артефакт. Код находится в системе котроля версий, шаги сборки CI/CD - тоже там (может быть в разных системах)
  * В любой момент мы можем создать артефакт из исходников

Сборка
Сервер
непрерывной
интеграции
Система
контроля
версий
Тестирование
Результат
Commit
Результат
Команда разработки

![approaches-01](/11-microservices-03-approaches/Files/approaches-01.png)

#### 5Непрерывная интеграция и микросервисы      - 00:05:10

> В микросервисной архитектуре непрерывная интеграция становится обязательной.
> Когда много сервисов, без автоматизации не обойтись для снижения влияния человеческого фактора на процесс поставки артефакта сборки и дальше на поставкку сервисов на прод.

* Когда много сервисов, то есть разные подходы:
  * Можно хранить код всех сервисов в одном большом репозитории и на каждый комит каждого сервиса собирать все что есть в этом репозитории
  * Можно хранить код всех сервисов в одном репозитории (-00:06:10 неразборчиво) и в папке отдельного коммита даст сборку только этого сервиса
  * Можно хранить код каждого сервиса в отдельном репозитории и для каждого сервиса настривать отдельную конфигурацию для сборки. Этот вариант наиболее выгодный.
  > Сервисы становятся независимыми друг от друга, начиная с кодовой базы и заканчивая артефактом сборки. У каждого сервиса свой артефакт. И они могут друг с другом общаться только через API. 
* Когда у нас очень много микросервисов, то для упрощения работы с такой схемой используют подходы, упрощающие создание и настройку сервисов.
  *  Это и автоматические способы по созданию и нименованию репозиториев, артефактов, конфигураций. Это конвенции и правила именования всего, что толко относится к сервису.
  *  Это может распространяться на другие аспекты - на мониторинг, сбор логов, трассировку, конфинурацию.
  *  У всех сервисов должен быть единый подход к именованию всех сущностей, которые относятся к сервису. Иначе будет сложно и разработчикам и эксплуатации  в том, что происходит в системе
  * Следующий аспект когда у нас один репозитори - один сервис это наличие у команды шаблонов структуры репозиториев для разных типов сервисов и разных стеков. Для того, чтобы каждый сервис в коде выглядел похоже. Чтобы был одинаковый набор папок, чтобы файлы назывались похоже, чтобы настройки для сборки были одинаковы и т.д.
  * Третий важный аспект - шаблоны конфигурации сборок с ситсеме сборки (например,в TeanCityесть шаблон, который можно подключать к репозиторию). Т.е. у нас есть много билд-конфигураций, набор шагов сборки у них одинаковый и которые настраиваются в зависимости от того к какому шаблону сборки они подключены

- 00:09:04 - 
- Таким образом подход "один сервис - один репозиторий" позволяет достичь максимальную независимость сервисов и при этом, если применить схемы по упрощению работы с большим кол-вом репозиториев у нас не слишком сильно усложнится система непрерывной интеграции.


Система хранения версий
Сервер непрерывной
интеграции
Service 1 Code Service 1 Build
Service 2 Code Service 2 Build
Service 3 Code Service 3 Build
Код каждого сервиса
хранится в отдельном
репозитории
Система хранения артефактов
Service 1
Version 1.2.3
Service 2
Version 2.0.7
Service 3
Version 1.0.1
Для каждого сервиса собирается
отдельный артефакт

![approaches-02](/11-microservices-03-approaches/Files/approaches-02.png)

### 6Непрерывная поставка       - 00:09:30
> Continues Delivery - это подход к разработке ПО, при котором оно производится кототкими итерациями и гарантирует, что ПО является стабильным и может быть передано в эксплуатацию в любое время. Но при этом сама передача обычно происходит вручную.
> Т.е. у нас есть такая система доставки, в которой по факту комита выполняется сборка, прогоняются юнит-тесты, после этого артефакт передается на приемку,
> в которой артефакт устанавливается на тестовую приемку (тоже может быть автоматически), прогоняются интеграционные тесты, нагрузочные тесты, и после подтвержения, что артефакт готов к выходу в прод уже вручную осуществляется его развертывание.
> Обычно для этого есть отдельная процедура (Релиз или что-такое). И информация об артефакте остается в системе учета задач

Код
Авто
Сборка
Авто
Тесты
●
●
●
●
Авто
Вруч
ную
Приёмка
Выкладка
Установка на тестовый контур
Интеграционные тесты
Нагрузочные тесты
Ручные тесты

![approaches-03](/11-microservices-03-approaches/Files/approaches-03.png)

### 7Непрерывная установка      -00:11:10
> Continues Deployment - этот подход использует автоматическое тестирование для проверки иззменений в коде на отсутствие регресса, на оостутствие повторений существующих ошибок и возникновение новых ошибок в существующем коде.
> И после автоматической проверки следует автоматическия установка ПО на продуктовый контур
* Continues Deployment - это следующий этап, к оторому следует стремится при разработке системы, основанной на микросервисах
Код
Авто
Сборка
Авто
Тесты
●
●
●
Авто
Авто
Приёмка
Выкладка
Установка на тестовый контур
Автоматические интеграционные тесты
Автоматические нагрузочные тесты

![approaches-04](/11-microservices-03-approaches/Files/approaches-04.png)


### 8Стенды / Контура       - 00:13:10
* Появляется необходимость доставки и развертывания на разные среды, предназначенных для различных целей
  * Стенд для приемочного тестирования
  * Стенд для команды разработки
  * Стенд для интеграционного тестирования между командами
  * Стенд для ручных тестировщиков
  * Боевой стенд
* Между стендами должно быть как можно меньше отличий по мере приближения к боевому.
* Это важно оптому, что в зависимомти от среды ПО может вести себя по разному
* Стараются держать хотябы одну тестовую среду полностью идентичную боевой среде и по настройкам и по ресурсам

* Управление стендами = это сложный и кропотливый процесс с вниманием к деталям

CI
Dev
Непрерывная сборка
● Сборка кода
● Unit-тесты
● Публикация артефактов сборки
Integration
UAT


Production


![approaches-05](/11-microservices-03-approaches/Files/approaches-05.png)

#### 9Непрерывное развертывание      -00:16:55
Варианты обновления сервисов на проде:
- Recreate
- Rolling deployment
- Blue-Green deployment
- Canary releases
- A/B testing
- Shadow

Стараются делать так, чтобы за одно изменение изменялся только один сервис

### 10Recreate      -00:18:18
Один из свмых простых способов.
Данный способ возможен при полной остановк всех сервисов. Значит есть простой в работе сервисов.
Также есть проблема в том, что при возникновении ошибок надо откатывться или чинить ошибку.
Это высокорисковый вариант при возникновении ошибки в процессе выкладки.
Но этот способ самый простой, дешевый и быстрый с точки зрения организации.
Такой подход можно использовать для вспомогательных систем у которых нет необходимости в постоянной и непрерывной работе, либо когда у системы есть интервалы, когда системой не пользуются.


До После
v1.0 v2.0
![approaches-06](/11-microservices-03-approaches/Files/approaches-06.png)

#### 11Мультисервис Recreate      - 00:20:00
При этом варианте происходит одновременное обновление нескольких сервисов. Это более рискованный вариант в случае ошибок в нескольких сервисах.
Вариант простой дешевый и быстрый. Неустойчив к ошибкам. С трудность в откатах.
После обновления нужно проверять каждый сервис чтобы все работало. Это может быть сложным, т.к. мы меняем много частей сразу.
Надо стараться минимизировать изменения. Для снижения риска сильного влияния на всю систему при ошибке.

До
v1.0
v2.7
После
v1.3
v3.8
v1.1
v2.8
v1.5
v4.0

![approaches-07](/11-microservices-03-approaches/Files/approaches-07.png)

#### 12Rolling deployment      -00:21:12
Это дефотный вариант для обновления версий подов в Kubernetes.
Постепенная замена всех экземпляров системы на новую версию.
Достаточно простой способ (из коробки) во многих системах.
Откат на предыдущую систему достаточно прост
Меньше риск при ошибке. Она может проявиться на для всех пользователей сразу.

* Минусы такого подхода:
  * необходимо обеспечить поддержку и работу одновременно разных версий сервисов
  * более длительный способ с точки зрения реализации обновления
  * 

После
До
1 Node
2 Nodes
OK?
v1.0
4 Nodes
3 Nodes
OK?
5 Nodes
OK?
6 Nodes
OK?
v2.0

![approaches-08](/11-microservices-03-approaches/Files/approaches-08.png)

#### 13Blue Green deployment     - 00:23:00

Используются два идентичных контура (Blue. Green). Один из контуров находится в работе, обрабатывает запросы. Другой контур работает, но не обрабатывает запросы (Standby). На контур в состоянии Standby устанавливается обновление и трафик переключается на него. Если ошибок нет, то так он и остается в работе. Если нет, то трафик переключается на первоначалный контур, Потом вносим исправления и опять пытаемся обновиться.

* Плюы такого подхода:
  * Мгновенное переключение и мгновенный откат при ошибках, т.к. у нас на стенде работают обе версии
* Минусы:
  * Необходимо содержать два идентичных контура (это может быть дорого)
  * Сложность развертывания сервисов с состоянием. Две версии сервисов должны работать одновременно. Только на уровне кластеров.
  * Есть риск потери запросов при переключении стенда, DNS или балансировщика
Blue Green deployment  достаточно популярный вариант.

До
После
Stand by Live Live Stand by
v1.2 v1.1 v1.2 v1.1

![approaches-09](/11-microservices-03-approaches/Files/approaches-09.png)

#### 14Canary deployment     - 00:24:50
Это больше подходы к выкладке, а не про обновление целиком. Скорее это техники для того, чтобы разворачивать сервис и выполнять дополнительные функции.
Канареечная выкладка характеризуется тем, что происходит направление запросов пользователей с одной версии на другую. Т.е. оно производится постепенно.
Здесь могут выделять специальную группу пользователей (Бетта тестирование). Может быть выбирается случайно какой-то % пользователей.
На трафике этих пользователей пытаются понять все л и нормально или нет. Выявляют ошибки, исправляют и т.д. опять обновляют пока все ошибки не исправят.
Далее можно постепенно увеличивать % пользователей, либо воспользоваться стандартными подходами, но более простыми: Rolling Deployment, Recreate, Blue Green.

* Плюсы такого подхода:
  * Простота отката
  * Возможность тестировать новый функционал, сервисы, гипотезы на небольшом % пользователей
  * Это дешевле Blue Green. Не нужно держать два стенда.
  * Наименее рисковый вариант с учетом цены.

* Минусы:
  * Должно пройти какое-то врмя прежде чем мы поймем что что-то не так
  * Сложность настроек для некоторых ситуаций
  * Необходимость работы одновременно нескольких разный версий
  * Длительность прверки после каждого шага обновления

До
После
10% запросов
70% запросов
OK?
v1.0
v1.1
v1.0
100% запросов
OK?
v1.1
v1.0
v1.1
![approaches-10](/11-microservices-03-approaches/Files/approaches-10.png)

#### 15A/B Testing   -0:28:45
Разные версии одного и того же сервиса могут одновременно работать кна одном и том же контуре в пределах фиксированного промежутка времени.
По результатам этих экспериментов должны быть собраны какие-то метрики для понимания того что эксперимент удачный или нет. И какой и звариантов нам подходит.
Это необязательно про Deployment. Мы гоаорим про развертывание.
Можно таким образом развертывать сервисы для эксперимнетов.

* Минусы: 
  * Сложность всей этой настройки
  * Итоги тестирования надо собирать и анализировать. А для этого нужны отдельные инструменты
  * Без распределенной трассировки здесь не обойтись. Иначен е будет понятно сервис с какой вервией как отработал

После
До
v1.2(B)
71%
v1.3 (D)
73%
v1.2 (C)
63%
v1.0
v1.0 (A) = 71%
v1.3

![approaches-11](/11-microservices-03-approaches/Files/approaches-11.png)

#### 16Shadow     -00:32:43

Теневое развертывание.
Используется для тестирования сервисов, используя боевые запросы.
При получении запроса балансировщик отправляет их на обе версии сервиса. Пользователю отправляется ответ от актуальной версии, а ответ от новой версии игнорируется или используется для сравнения с ответтом от текущей версии. Так можно увидеть регресс, измерить призводительность.
* В основном этот подход применяется для тестирования используюя боевой трафик, при этом никак не влияя нп ользователей.
* Выкатка на пользователей производится только после достиженя требований по стабильности и производительности.

* Минусы:
  * Дорого
  * Сложно в настройке
  * Анализировать сложно

Если мы занимаемся заменой какого-то сервиса, то это хороший вариант в плане того, что мы можем на боевом трафике проверить, что наш сервис, написанный по-новому (на новом языке, с новыми алгоритмами) работает с точки зрения внешнего потребителя точно так же как и предыдущая версия.
До
v1.0
После
v1.0
v2.0
![approaches-12](/11-microservices-03-approaches/Files/approaches-12.png)

#### 17Непрерывное развертывание      - 00:34:40

* Выводы про развертывание.
  * Rolling Deployment, Blue Green - это лучшие варианты и стратегии, которые можно использовать в бою.
  * Blue Green и Shadow требуют дополнительный набор ресурсов. Blue Green - двойного, что сильно влиятяет на бюджет


|Стратегия|Отсутствие остановки|Тестирование на реальных запросах|Тестирование действий пользователей|Стоимость|Длительность отката|Влияние на пользователей|Сложность|
|-|-|-|-|-|-|-|-|
Recreate| ❌|❌|❌| 💲 |🕔🕔🕔| 󰣻󰣻󰣻 |
Rolling| ✔| ❌| ❌| 💲 |🕔🕔🕔| 󰣻 |🔬
Blue Green| ✔ |❌| ❌| 💲💲💲 ||󰣻󰣻 |🔬🔬
Canary| ✔ |✔| ❌| 💲 |🕔 |󰣻 |🔬
A/B Testing| ✔ |✔| ✔| 💲 |🕔| 󰣻 |🔬🔬🔬
Shadow| ✔| ✔| ❌| 💲💲💲|||🔬🔬🔬

![approaches-13](/11-microservices-03-approaches/Files/approaches-13.png)

### 18Тестирование      - 00:36:05

#### 19Типы тестов
* Главное:
  * Микросервисы базируются на автотестах, иначе автоматического развертывания и доставки добиться не получится. Просто потому что ручное тестирование долго и не надежно.

* Квадрант тестирования:
  * Технологические тесты помогают разрабочикам создавать систему
  * Бизнес направленные тесты. Они помогают неискушенным в технологиях удостовериться в работе систем

Предпочтение надо отдавать небольшим легкоповторяемым автоматизированным тестам
Иногда на обойтись и без ручных тестов, низкоуровневого.

В микросервисной системе, если от нее зависит жизнь и здоровье человека необходимо использовать автотестирование

![approaches-14](/11-microservices-03-approaches/Files/approaches-14.png)

### 20Пирамида тестирования    - 00:39:05
* Пирамида показывает пропорции в которых нужно использоват тесты
  * End to End тесты дают больше уверенности в правильном поведени систем, их функциональности. Но такие тесты дорогие и медленные. Должно быть не много.
  * Unit Test быстрые и дешевые, но они проверяют код в изоляции от остального кода. Таких тестов должно быть много чтобы определить что у нас все работает так как нужно
  * Service


![approaches-15](/11-microservices-03-approaches/Files/approaches-15.png)

### 21Тесты - часть процесса развертывания   -00:41:25

Тесты должны быть частью сборки и развертывания (пайплайн). Чем раньше система упадет, если в ней есть ошибка, тем это лучше.
Не должны запускаться интеграционные тестирования, если не прошли юнит-тесты. Пока разработчик не починил юнит-тест, дальше пайплай не должен идти.
Задача DevOps- обеспечить работу пайплайн. А тесты пишут или разработчики или тестироващики.

Unit Tests
Service Tests
End to End Tests
Цепочка-сборка
прерывается как
можно раньше, чтобы
сократить время
обратной связи.

![approaches-16](/11-microservices-03-approaches/Files/approaches-16.png)

### 22Безопасность    - 00:42:50

### 23Аутентификация и авторизация   -00:44:40
- Идентификация - процедура выявления идентификатора субъекта в системе
- Аутентификация - процедура проверки подлинности
- Авторизация - процедура проверки прав на выполнение определенных операций

В микросервисной архитектуре становится актуальной задача идентификации пользователя на всех сервисах одновременно при его аутентификации в системе

### 24Single Sign On  (SSO)  -00:49:35

Это подход к аутентификации, который позволяет пользователям аутентифицироваться в нескольких независимых системах, используя единый идентификатор и пароль
Login 1 Service 1 Service 1
Login 2 Service 2 Service 2
SSO
Login 3 Service 3 Service 3
Login 4 Service 4 Service 4

![approaches-17](/11-microservices-03-approaches/Files/approaches-17.png)

### 25Межсервисная аутентификация и авторизация    - 00:51:00

Сервисы тоже должны общаться между собой в рамках системы. Их вызовы также могут быть перехвачены, скомпрометированы.
Нам надо решить какую межсервисную аутентификацию использовать чтобы сервисы работали безопасно

1. Без авторизации
2. Пользовательский токен - таскать с собой токен от аутентификации пользователя
3. Простая HTTP авторизация (Basic - авторизация). Позволяет 
4. OAuth
5. Client Certiﬁcates
6. HMAC - хэш-код от всего запроса
7. API Keys

![approaches-18](/11-microservices-03-approaches/Files/approaches-18.png)

### 26Без аутентификации   - 00:53:19
Используется в том случае, если внутри организации можно доверять всем. Сеть закрытая. Но попав в нутрь сети злоумышленник может делать что угодно.
Это очень рисковано. Нужн охорошо взвешивать риски.

schema://host:port
Service 1
Service 2

![approaches-19](/11-microservices-03-approaches/Files/approaches-19.png)

### 27Propagate User Identity    - 00:54:35

При наличии SSO решения можно использовать токен, выданный при SSO для коммуникаций между сервисами. Это дает дополнительные возможности пользователю.  Втокен можно зашить информацию о возможностях пользователя.

* Минусы:
  * Сложная система привелегий. Чем больше сервисов и ролей, тем сложнее будут система
  * Могут быть ситуации, когда сервисы взаимодействуют между собой без участия ползователя
login + password
schema://host:port
SSO
Client Token
Service 1
Service 2

![approaches-20](/11-microservices-03-approaches/Files/approaches-20.png)

### 8HTTP Basic Auth   -00:58:25
Простая HTTP авторизация используя заголовок HTTP
Никакой защиты нет. Заголовок отправляется в Base64. Это очень простой вариант.
Безопаснее использовать HTTPS.
Логины и прали должны где-то храниться, чтобы микросервисы могли ими пользоваться.

```
https://host:port
Authorization: Basic base64(<username>:<password>)
Service 1
Service 2
HTTPS Server
Certiﬁcate
Private Key
Поиск логина и пароля в Базе Данных
```
 
![approaches-21](/11-microservices-03-approaches/Files/approaches-21.png)

### 29OAuth2    -00:59:52

OAuth2 - Открытый протокол авторизации, предназначенный для обеспечения возможности предоставления доступа к данным третьей стороне.
На этом протоколе работают, в частности, Google аторизации, вход через Facebookи т.д.
Auth2 позволяет для межсервисной авторизации использовать Client Credentials. Он совмещает аутентификацию и авторизацию. Он заменяет Access Token, в котором зашита вся информация о сервисе, его правах и возможностях.
Это открытый протокол. Для бльшинства платформ есть бибилиотеки. Само управление логином и паролем в итоге реализовано на центральном сервисе аутентификации. И так как OAuth2 предполагает использование JIT какого-то там токена (стандартный токен, использующийся для аутентификации и авторизации). В этот токен мы можем поместить дополнительную инфу. Благодарая этому такой подход снижает зависимость сервисов от сервиса аутентификации (даже если такой сервис ляжет, пользователи с токенами продолжат работать). Проверка токена не предполагает обращение к сервису авторизации. Токен подписан с помощью криптографических инструментов, в нем есть вся необходимая информация для того, чтобы идентифицировать вызывающую сторону, определить какие права у нее есть и т.д. и т.п.
* Минус:
  *  Этот сервис нужно ставить
  *  Должен быть выбор какого-то решения, которое обеспечивает необходимые возможности, которые требуются в конкретной системе

Хорошим вариантом было бы использование для SSO пользователей готовый сервис с поддержкой pan id connect. На основе его стрить авторизацию между сервисами, построенными на протоколе OAuth2


OAuth2 Service
access_token
Service 1
Service 2
https://host:port
```
 Authorization: Bearer <access_token>`
```
![approaches-22](/11-microservices-03-approaches/Files/approaches-22.png)

### 30Client Certiﬁcates    -00:02:30
Клиентский сертификат (мьючуал TLS)
Это наиболее безопасный вариант для межсервисной коммуникации.
* Плюсы:
  * Применяются стандартные подходы TLS, Все это встроено в протокол HTTPS и по суи мы опираемся на стандарт
  * Максимальная безопасность коммуникаций. Шифрование идет в обе стороны
  * Т.к. сертификаты тоже есть стандартные X502, есть возможность строить цепочки сертификатов, организации различных иерархий при выпуске сертификата - это обеспечивает гибкость такого подхода в плане настройки
* Минусы:
  * Необходимо обеспечить выпуск сертификатов, их управление, хранени релокейшен листов и т.д.

Обычно такой подход применяется когда важно безопасность коммуникаций при открытых сетях коммуникаций
Такой подход выбирают для решения IoIT в которых передается важная и чувствительная информация.

Certiﬁcate Authority
Verify Server Certiﬁcate
Client
Certiﬁcate Server
Certiﬁcate
Public Key Public Key
Service 1
Service 2
Server
Certiﬁcate
Client
Certiﬁcate
Private
Key
Verify Client Certiﬁcate
https://host:port
Private
Key
![approaches-23](/11-microservices-03-approaches/Files/approaches-23.png)

### 31Hash-based Message Authentication Code (HMAC)     - 00:04:45

Самый интересный вид аутентификации. Это код аутентификации сообщения, основанный на хэш-функции.
Метод основан на том, что клиент подписывает содержимое запроса с помощью приватного ключа (секрет). Сервер при получении запроса вычисляет подпись по тем же данным и сравнивает клиентскую подпись с вычесленной. И сервер и клиент обладают одним секретом. Клиент берет поределенные параметры отправляемого запроса (адрес, заголовки, боди), вычисляет хэш-функцию от этого набора данных и отправляет ее вместе с запросом. Сервер принимает запрос, извлекает из него все теже параметры. У сервера тоже есть секрет. Он по тому же самому алгоритму вычисляет хэш-код и сравнивает точто прислал клиент с тем, что вычислсл сервер. Если произошло совпадение, значит у клиента есть секрет и мы можем ему доверять. Если не совпадает, значит секрета нет и это не клиент, а злоумышленник и доверять ему нельзя. Секреты на сервере и на клиенте заранее подготоваливаются не в онлайн, а используя другие каналы. 
* Минус:
  * Данный подход не защищает от атаки повтором
  * Лучше использовать HTTPS, т.к. данный подход гарантирует что запрос подал тот, кто имеет секрет, но он не защищает данные во время передачи.

HMAC часто используется облачными провайдерами в своих облачных решениях.
HMAC - это не стандарт. Мы говорим просто о подходе. Каждый, кто его реализует, система, облачный провайдер, компания, которая хочет такую аутентификацию раелизовать, она реализует по своему. 
Есть какие-то OpenSource реализации, но в целом нет никакого стандарта. Его каждый раелизует как хочет. Это и плюс и минус.
```
https://host:port
Authorization: HMAC-SHA256 <id>:<signature>
Service 1
Service 2
id
secret
id
id secret
id
id secret
secret
secret
CanonicalRequest
Timestamp
+ HTTP Verb
+ Canonical URL
+ Canonical Query String
+ Canonical Headers
+ Signed Headers
+ hash(SHA256, Payload)
Signature Calculation
StringToSign
“HMAC”
+ Timestamp
+ hex(hash(SHA256, CanonicalRequest))
Signature
hex(hmac(SHA256, secret, StringToSign))
```
 
![approaches-24](/11-microservices-03-approaches/Files/approaches-24.png)

### 32API Keys    - 01:09:05

Это уникальный аутентификатор, который нужен для того, чтобы аутентифицировать вызывающую сторону. Это не стандарт, а просто шаблон. Поэтому разные системы могут реализовывать его по разному. (используют, заголовки, файлы-куки).
Считается безопасным только при использовании HTTPS.

* Минусы:
  * Низкий уровень безопасности ( при потере API Keys лучше его просто поменять.)
  * необходимость применения HTTPS, TLS



1. Заголовок
https://host:port
X-API-Key: 2fb96c97-d401-475a-8f12-ed7b9346fedb
2. Строка запроса
https://host:port?api_key=2fb96c97-d401-475a-8f12-ed7b9346fedb
Service 1
Service 2
Верификация API Key по Базе Данных

![approaches-25](/11-microservices-03-approaches/Files/approaches-25.png)
  
### 33Межсервисная аутентификация и авторизация    -01:10:15
Выбор зависит от решаемой задачи и требования безопасности, от проекта и от цели, решаемой этим проектом.

1. Без авторизации
2. Пользовательский токен
3. Простая HTTP авторизация
4. OAuth
5. Client Certiﬁcates
6. HMAC
7. API Keys

### 34Мониторинг     -01:11:40

### 35Сбор метрик
Host 1
Host 2
Каждый сервис
публикует метрики
Host N
На регулярной основе
считывает и сохраняет
значения метрик
http://host/metrics
Prometheus
Graphana
InﬂuxDb

### 36Сбор логов
Host 1 Host 2 Host N
Application
log Application
log Application
log
Logstash Logstash Logstash
Elastic Search Kibana

### 37Сбор трассировки
Host 1 Host 2 Host N
Jaegеr Agent Jaegеr Agent Jaegеr Agent
Jaegеr Collector
Cassandra
Jaegеr UI

### 38Мониторинг
1. Сбор метрик
2. Сбор логов
3. Сбор трассировки
Важно стандартизировать метрики, логи и трассировку
для всех сервисов.

### 39Итоги
● Узнали важность непрерывной поставки для микросервисной
архитектуры
● Познакомились со способами развертывания микросервисов
● Узнали про разные виды тестирования и изучили влияние пирамиды
тестирования на результат
● Разобрали разные способы обеспечения аутентификации и авторизации
● Познакомились со способами мониторинга: метрики, логи, трассировка

### 40Домашнее задание
Давайте посмотрим ваше домашнее задание.
● Вопросы по домашней работе задавайте в чате мессенджера Slack.
● Задачи можно сдавать по частям.
● Зачёт по домашней работе проставляется после того, как приняты
все задачи.

### 41Задавайте вопросы и
пишите отзыв о лекции!
Михаил Триполитов
Михаил Триполитов
